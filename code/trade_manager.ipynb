{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c352274",
   "metadata": {},
   "source": [
    "# Trade Manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b048f9a5",
   "metadata": {},
   "source": [
    "# Buy agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a3d6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.loader import load_trading_system_config\n",
    "config = load_trading_system_config(\"config/data_config.yaml\")\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26131b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.buy_agent_trainer import BuyAgentTrainer\n",
    "from agents.sell_agent_trainer import SellAgentTrainer\n",
    "\n",
    "buy_trainer = BuyAgentTrainer(\n",
    "    ticker=\"AAPL\",\n",
    "    window_size=30,\n",
    "    horizon=20,\n",
    "    transaction_cost=0.001,\n",
    "    lambda_dd=0.05,\n",
    "    lambda_vol=0.01,\n",
    "    hold_penalty_long=0.0,\n",
    "    device=\"cpu\",\n",
    ")\n",
    "\n",
    "buy_trend_history = buy_trainer.train_trend_filtered(\n",
    "    n_episodes=200,\n",
    "    verbose=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc9b20c",
   "metadata": {},
   "source": [
    "# Sell Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0cf21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Build SellTrainer\n",
    "sell_trainer = SellAgentTrainer(\n",
    "    ticker=\"AAPL\",\n",
    "    window_size=30,\n",
    "    horizon=20,\n",
    "    transaction_cost=0.001,\n",
    "    min_steps_before_sell=1,\n",
    "    lambda_dd=0.05,\n",
    "    lambda_vol=0.01,\n",
    "    hold_penalty_long=0.0,\n",
    "    device=\"cpu\",\n",
    ")\n",
    "\n",
    "# 2) Train SellAgent on BuyAgent entries\n",
    "sell_history = sell_trainer.train_on_buy_entries(\n",
    "    buy_agent=buy_trainer.agent,\n",
    "    n_episodes=300,\n",
    "    verbose=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff941b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.trade_manager import TradeManager\n",
    "# from agents.buy_agent_trainer import BuyAgentTrainer\n",
    "# from agents.sell_agent_trainer import SellAgentTrainer\n",
    "import numpy as np\n",
    "\n",
    "tm = TradeManager(\n",
    "    buy_trainer=buy_trainer,\n",
    "    sell_trainer=sell_trainer,\n",
    "    cfg_path=\"config/data_config.yaml\",\n",
    ")\n",
    "\n",
    "print(\"Trend filter True count:\", np.sum(tm.sma_short > tm.sma_long))\n",
    "\n",
    "# Inspect BuyAgent confidence over entire dataset\n",
    "import torch\n",
    "confs = []\n",
    "for i in range(len(tm.state_df)):\n",
    "    state = tm.state_df.iloc[i].values.astype(np.float32)\n",
    "    with torch.no_grad():\n",
    "        s = torch.from_numpy(state).unsqueeze(0).to(tm.buy_agent.device)\n",
    "        q = tm.buy_agent.q_net(s)[0].cpu().numpy()\n",
    "        p = np.exp(q - q.max()) / np.exp(q - q.max()).sum()\n",
    "        confs.append(p[1])\n",
    "\n",
    "print(\"Average BUY confidence:\", np.mean(confs))\n",
    "print(\"Max BUY confidence:\", np.max(confs))\n",
    "print(\"Min BUY confidence:\", np.min(confs))\n",
    "\n",
    "results = tm.run_backtest(greedy=True)\n",
    "\n",
    "\n",
    "\n",
    "equity = results[\"equity_curve\"]\n",
    "trades = results[\"trades\"]\n",
    "\n",
    "print(\"Trades executed:\", len(trades))\n",
    "print(\"First 5 trades:\")\n",
    "for t in trades[:5]:\n",
    "    print(t)\n",
    "\n",
    "print(\"Final equity:\", equity[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea5ccdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "equity = results[\"equity_curve\"]\n",
    "trades = results[\"trades\"]\n",
    "\n",
    "print(\"Trades executed:\", len(trades))\n",
    "print(\"First 5 trades:\")\n",
    "for t in trades[:5]:\n",
    "    print(t)\n",
    "\n",
    "print(\"Final equity:\", equity[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36301b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(equity)\n",
    "plt.title(\"Equity Curve (After MP Training)\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Equity\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32e6926",
   "metadata": {},
   "source": [
    "# After refactoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45460f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from config.loader import load_config\n",
    "from agents.buy_agent_trainer import BuyAgentTrainer\n",
    "from agents.sell_agent_trainer import SellAgentTrainer\n",
    "from scripts.trade_manager import TradeManager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b74205d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TradeManagerConfig(cooldown_steps=5, sell_horizon=20, buy_min_confidence=0.5, use_trend_filter=True, ma_short=10, ma_long=30)\n"
     ]
    }
   ],
   "source": [
    "config = load_config(\"config/config.yaml\")\n",
    "print(config.trade_manager)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df418ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BuyTrainer] Raw dataset: (1224, 10)\n",
      "[BuyTrainer] After dropna: (1224, 10)\n",
      "[BuyTrainer] Rolling state_df shape: (1194, 270)\n",
      "[BuyTrainer] state_dim=270, actions=2\n",
      "[BuyTrainer] Warmup set to: 238\n",
      "[Buy Ep 1/20] Reward=0.9083 | Eps=0.773 | Steps=1193 | Buffer=1193 | Avg10=0.9083\n",
      "[Buy Ep 10/20] Reward=0.4525 | Eps=0.050 | Steps=1193 | Buffer=11930 | Avg10=0.9781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Buy Ep 20/20] Reward=0.7477 | Eps=0.050 | Steps=1193 | Buffer=23860 | Avg10=1.0023\n",
      "Collected BUY entries: 0\n",
      "First 10: []\n",
      "[SellTrainer] Raw dataset: (1224, 10)\n",
      "[SellTrainer] After dropna: (1224, 10)\n",
      "[SellTrainer] state_df shape: (1194, 270)\n",
      "[SellTrainer] prices shape: (1194,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "SellAgentTrainer: buy_entry_indices must be a non-empty 1D array.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFirst 10:\u001b[39m\u001b[38;5;124m\"\u001b[39m, buy_entry_indices[:\u001b[38;5;241m10\u001b[39m])\n\u001b[1;32m     12\u001b[0m sell_trainer \u001b[38;5;241m=\u001b[39m SellAgentTrainer(ticker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAAPL\u001b[39m\u001b[38;5;124m\"\u001b[39m, config\u001b[38;5;241m=\u001b[39mconfig, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m sell_hist \u001b[38;5;241m=\u001b[39m \u001b[43msell_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarmup_dynamic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuy_entry_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuy_entry_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSell final reward:\u001b[39m\u001b[38;5;124m\"\u001b[39m, sell_hist[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepisode_rewards\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/Documents/uni/FinalProject/cm_3070_FP/code/agents/sell_agent_trainer.py:160\u001b[0m, in \u001b[0;36mSellAgentTrainer.train\u001b[0;34m(self, n_episodes, warmup_dynamic, verbose, buy_entry_indices)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSellAgentTrainer.train() requires buy_entry_indices.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must pass the BUY entry indices generated by BuyAgent.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m     )\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_dataset_and_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuy_entry_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuy_entry_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/uni/FinalProject/cm_3070_FP/code/agents/sell_agent_trainer.py:94\u001b[0m, in \u001b[0;36mSellAgentTrainer._build_dataset_and_env\u001b[0;34m(self, buy_entry_indices)\u001b[0m\n\u001b[1;32m     92\u001b[0m buy_entry_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(buy_entry_indices, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buy_entry_indices\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buy_entry_indices) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     95\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSellAgentTrainer: buy_entry_indices must be a non-empty 1D array.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     96\u001b[0m     )\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;241m=\u001b[39m SellEnv(\n\u001b[1;32m    100\u001b[0m     state_df\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate_df,\n\u001b[1;32m    101\u001b[0m     prices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprices,\n\u001b[1;32m    102\u001b[0m     entry_indices\u001b[38;5;241m=\u001b[39mbuy_entry_indices,\n\u001b[1;32m    103\u001b[0m     config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig,\n\u001b[1;32m    104\u001b[0m )\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# Agent hyperparams come from config.agent\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: SellAgentTrainer: buy_entry_indices must be a non-empty 1D array."
     ]
    }
   ],
   "source": [
    "buy_trainer = BuyAgentTrainer(ticker=\"AAPL\", config=config, device=\"cpu\")\n",
    "buy_hist = buy_trainer.train(n_episodes=20, warmup_dynamic=True, verbose=True)\n",
    "\n",
    "buy_entry_indices = buy_trainer.collect_buy_entry_indices(\n",
    "    buy_min_confidence=0.48,   # tune here\n",
    "    use_trend_filter=False\n",
    ")\n",
    "\n",
    "print(\"Collected BUY entries:\", len(buy_entry_indices))\n",
    "print(\"First 10:\", buy_entry_indices[:10])\n",
    "\n",
    "sell_trainer = SellAgentTrainer(ticker=\"AAPL\", config=config, device=\"cpu\")\n",
    "sell_hist = sell_trainer.train(\n",
    "    n_episodes=50,\n",
    "    warmup_dynamic=True,\n",
    "    verbose=True,\n",
    "    buy_entry_indices=buy_entry_indices,\n",
    ")\n",
    "print(\"Sell final reward:\", sell_hist[\"episode_rewards\"][-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0713b4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "sell_trainer = SellAgentTrainer(\n",
    "    ticker=\"AAPL\",\n",
    "    config=config,\n",
    "    device=\"cpu\",\n",
    ")\n",
    "\n",
    "sell_rewards = sell_trainer.train(\n",
    "    n_episodes=50,\n",
    "    warmup_dynamic=True,\n",
    "    verbose=True,\n",
    "    buy_entry_indices=buy_entry_indices,\n",
    ")\n",
    "\n",
    "print(\"\\n[SellAgent] Training complete\")\n",
    "print(\"Final reward:\", sell_rewards[\"episode_rewards\"][-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.14",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
