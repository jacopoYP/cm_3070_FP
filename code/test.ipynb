{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41e6d157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d52315a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "from pipeline.build_dataset import make_state_frame\n",
    "import yaml\n",
    "\n",
    "cfg = yaml.safe_load(open(\"config/data_config.yaml\"))\n",
    "dataset = make_state_frame(\"AAPL\", cfg)\n",
    "# print(dataset.tail())\n",
    "# dataset.tail().isna().sum()\n",
    "# raw = fetch_ohlcv(\"AAPL\", cfg[\"start_date\"], cfg[\"end_date\"])\n",
    "# print(raw.index[-5:], dataset.index[-5:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8874bd",
   "metadata": {},
   "source": [
    "## Assembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92a58baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial obs shape: (270,) dtype: float32\n",
      "step=0, reward=0.01565893366932869, done=True\n",
      "step=1000, reward=0.0, done=False\n",
      "step=2000, reward=0.0, done=False\n",
      "step=3000, reward=-0.005347793456166983, done=True\n",
      "step=4000, reward=0.0, done=False\n",
      "step=5000, reward=0.0, done=False\n",
      "step=6000, reward=0.0, done=False\n",
      "step=7000, reward=0.01565893366932869, done=True\n",
      "step=8000, reward=0.0, done=False\n",
      "step=9000, reward=0.0, done=False\n",
      "Random roll-out finished without crash.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
     ]
    }
   ],
   "source": [
    "from pipeline.state_assembler import StateAssembler\n",
    "\n",
    "# removing empty items\n",
    "dataset = dataset.dropna().copy()\n",
    "\n",
    "# # Assemble rolling-window states\n",
    "# assembler = StateAssembler(\n",
    "#     feature_cols=[c for c in dataset.columns if c != \"price\"],\n",
    "#     window_size=30\n",
    "# )\n",
    "# state_df = assembler.assemble(dataset)\n",
    "# # print(state_df.shape)\n",
    "# # print(state_df.tail())\n",
    "# # 3. Align prices by using the *same index* as state_df\n",
    "# prices = dataset.loc[state_df.index, \"price\"]\n",
    "\n",
    "# print(\"state_df shape:\", state_df.shape)\n",
    "# print(\"prices shape:\", prices.shape)\n",
    "from envs.buy_env import BuyEnv\n",
    "# from state_assembler import StateAssembler\n",
    "import numpy as np\n",
    "\n",
    "# Assuming youâ€™ve already built `dataset` with your indicators + price\n",
    "feature_cols = [\"return_1d\", \"rsi14\", \"macd_diff\", \"bb_b\",\n",
    "                \"atr14\", \"roc10\", \"obv\", \"mfi14\", \"willr14\"]\n",
    "\n",
    "assembler = StateAssembler(feature_cols=feature_cols, window_size=30)\n",
    "state_df = assembler.assemble(dataset)\n",
    "\n",
    "# Align prices index with state_df\n",
    "prices = dataset.loc[state_df.index, \"price\"]\n",
    "\n",
    "env = BuyEnv(state_df, prices, horizon=5, transaction_cost=0.001)\n",
    "\n",
    "obs = env.reset()\n",
    "print(\"Initial obs shape:\", obs.shape, \"dtype:\", obs.dtype)\n",
    "\n",
    "for step in range(10_000):\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    if step % 1000 == 0:\n",
    "        print(f\"step={step}, reward={reward}, done={done}\")\n",
    "    if done:\n",
    "        obs = env.reset()\n",
    "\n",
    "print(\"Random roll-out finished without crash.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a0e495",
   "metadata": {},
   "source": [
    "## Buy Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64d1f3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial state shape: (270,)\n",
      "step=0, action=0, reward=0.0000, done=False, info={'t': 1, 'price': 47.02927780151367}\n",
      "step=1, action=1, reward=0.0085, done=True, info={'t': 2, 'price': 47.76933670043945}\n"
     ]
    }
   ],
   "source": [
    "from envs.buy_env import BuyEnv\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# # 3) Align prices\n",
    "\n",
    "# dataset = dataset.dropna().copy()\n",
    "# prices = dataset[\"price\"].copy()\n",
    "# states = dataset.drop(columns=[\"price\"]).copy()\n",
    "\n",
    "# price_aligned = dataset.loc[state_df.index, \"price\"]\n",
    "\n",
    "# print(\"state_df shape:\", state_df.shape)\n",
    "# print(\"prices shape:\", prices.shape)\n",
    "\n",
    "# print(\"NaNs in state_df:\", np.isnan(state_df.values).sum())\n",
    "# print(\"NaNs in prices:\", np.isnan(prices.values).sum())\n",
    "\n",
    "\n",
    "# 4) Create environment\n",
    "# env = BuyEnv(state_df, price_aligned, horizon=5, transaction_cost=0.001)\n",
    "env = BuyEnv(state_df, prices, horizon=5, transaction_cost=0.001)\n",
    "\n",
    "# 5) Smoke test\n",
    "obs = env.reset()\n",
    "print(\"Initial state shape:\", obs.shape)\n",
    "\n",
    "for step in range(5):\n",
    "    action = env.action_space.sample()  # random action\n",
    "    next_obs, reward, done, info = env.step(action)\n",
    "    print(f\"step={step}, action={action}, reward={reward:.4f}, done={done}, info={info}\")\n",
    "    if done:\n",
    "        break\n",
    "\n",
    "# print(\"Initial obs shape:\", obs.shape)\n",
    "\n",
    "# from stable_baselines3 import DQN\n",
    "\n",
    "# model = DQN(\"MlpPolicy\", env, verbose=1)\n",
    "# model.learn(total_timesteps=5_000)\n",
    "\n",
    "# obs = env.reset()\n",
    "# action = model.predict(obs, deterministic=True)[0]\n",
    "# print(\"Greedy action:\", action)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "554169c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from stable_baselines3 import DQN\n",
    "# from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "# # # Rebuild env exactly as above\n",
    "# # feature_cols = [\"return_1d\", \"rsi14\", \"macd_diff\", \"bb_b\",\n",
    "# #                 \"atr14\", \"roc10\", \"obv\", \"mfi14\", \"willr14\"]\n",
    "# # assembler = StateAssembler(feature_cols=feature_cols, window_size=30)\n",
    "# # state_df = assembler.assemble(dataset)\n",
    "# # prices = dataset.loc[state_df.index, \"price\"]\n",
    "\n",
    "# # env = BuyEnv(state_df, prices, horizon=5, transaction_cost=0.001)\n",
    "\n",
    "# # Wrap explicitly in DummyVecEnv (SB3 does this internally, but we make it explicit)\n",
    "# vec_env = DummyVecEnv([lambda: env])\n",
    "\n",
    "# model = DQN(\n",
    "#     \"MlpPolicy\",\n",
    "#     vec_env,\n",
    "#     verbose=1,\n",
    "#     learning_rate=1e-4,\n",
    "#     buffer_size=5_000,\n",
    "#     batch_size=32,\n",
    "#     train_freq=1,\n",
    "#     gradient_steps=1,\n",
    "#     exploration_fraction=0.1,\n",
    "#     exploration_final_eps=0.01,\n",
    "#     target_update_interval=500,\n",
    "# )\n",
    "\n",
    "# model.learn(total_timesteps=5_000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b37029",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m set_seeds(\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Make sure we run from project root\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m os\u001b[38;5;241m.\u001b[39mchdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(\u001b[38;5;18;43m__file__\u001b[39;49m)))\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# 1) create trainer for one ticker (e.g. AAPL)\u001b[39;00m\n\u001b[1;32m     26\u001b[0m trainer \u001b[38;5;241m=\u001b[39m BuyAgentTrainer(\n\u001b[1;32m     27\u001b[0m     cfg_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig/data_config.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     28\u001b[0m     ticker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAAPL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     transaction_cost\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m,\n\u001b[1;32m     32\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "# scripts/train_buy_ddqn.py\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from agents.buy_agent_ddqn import BuyAgentTrainer\n",
    "\n",
    "def set_seeds(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Just to be safe / reproducible\n",
    "    set_seeds(42)\n",
    "\n",
    "    # Make sure we run from project root\n",
    "    os.chdir(os.path.dirname(os.path.dirname(__file__)))\n",
    "\n",
    "    # 1) create trainer for one ticker (e.g. AAPL)\n",
    "    trainer = BuyAgentTrainer(\n",
    "        cfg_path=\"config/data_config.yaml\",\n",
    "        ticker=\"AAPL\",\n",
    "        window_size=30,\n",
    "        horizon=5,\n",
    "        transaction_cost=0.001,\n",
    "    )\n",
    "\n",
    "    # 2) quick training run (PoC)\n",
    "    #    start small (e.g. 50 episodes) to make sure everything works\n",
    "    rewards = trainer.train(\n",
    "        n_episodes=50,\n",
    "        max_steps_per_episode=None,  # let env end naturally\n",
    "        warmup_steps=500,\n",
    "    )\n",
    "\n",
    "    print(\"Last 10 episode rewards:\", rewards[-10:])\n",
    "\n",
    "    # 3) run greedy policy once to see how it behaves\n",
    "    greedy_policy = trainer.make_greedy_policy()\n",
    "    total_reward, steps = greedy_policy(trainer.env)\n",
    "    print(f\"Greedy run: total_reward={total_reward:.4f}, steps={steps}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0c66df",
   "metadata": {},
   "source": [
    "## Training agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76062458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from agents.buy_agent_ddqn import BuyAgentDDQN\n",
    "\n",
    "# # Reuse env from previous block\n",
    "# buy_agent = BuyAgentDDQN(env, learning_rate=1e-4, gamma=0.99)\n",
    "\n",
    "# # Short training run just to validate everything works\n",
    "# buy_agent.train(timesteps=10_000)\n",
    "\n",
    "# # Save model\n",
    "# buy_agent.save(\"results/models/buy_agent_aapl_ddqn\")\n",
    "\n",
    "# # Test one greedy decision\n",
    "# obs = env.reset()\n",
    "# action = buy_agent.act(obs)\n",
    "# print(\"Greedy action at start:\", action)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.14",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
