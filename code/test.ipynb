{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41e6d157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.9.1-cp310-none-macosx_11_0_arm64.whl (74.5 MB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.24.1-cp310-cp310-macosx_11_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchaudio\n",
      "  Downloading torchaudio-2.9.1-cp310-cp310-macosx_11_0_arm64.whl (805 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.9/805.9 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting jinja2\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/jacopo/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torch) (4.15.0)\n",
      "Collecting networkx>=2.5.1\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Collecting fsspec>=0.8.5\n",
      "  Using cached fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
      "Collecting sympy>=1.13.3\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Collecting pillow!=8.3.*,>=5.3.0\n",
      "  Using cached pillow-12.0.0-cp310-cp310-macosx_11_0_arm64.whl (4.7 MB)\n",
      "Requirement already satisfied: numpy in /Users/jacopo/.pyenv/versions/3.10.14/lib/python3.10/site-packages (from torchvision) (2.2.6)\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Using cached markupsafe-3.0.3-cp310-cp310-macosx_11_0_arm64.whl (12 kB)\n",
      "Installing collected packages: mpmath, sympy, pillow, networkx, MarkupSafe, fsspec, filelock, jinja2, torch, torchvision, torchaudio\n",
      "Successfully installed MarkupSafe-3.0.3 filelock-3.20.0 fsspec-2025.10.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 pillow-12.0.0 sympy-1.14.0 torch-2.9.1 torchaudio-2.9.1 torchvision-0.24.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d52315a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "from pipeline.build_dataset import make_state_frame\n",
    "import yaml\n",
    "\n",
    "cfg = yaml.safe_load(open(\"config/data_config.yaml\"))\n",
    "dataset = make_state_frame(\"AAPL\", cfg)\n",
    "# print(dataset.tail())\n",
    "# dataset.tail().isna().sum()\n",
    "# raw = fetch_ohlcv(\"AAPL\", cfg[\"start_date\"], cfg[\"end_date\"])\n",
    "# print(raw.index[-5:], dataset.index[-5:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8874bd",
   "metadata": {},
   "source": [
    "## Assembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92a58baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- ENV DEBUG ----\n",
      "states shape: (1194, 270) dtype: float64\n",
      "prices shape: (1194,) dtype: float64\n",
      "nan in states: 0\n",
      "nan in prices: 0\n",
      "--------------------\n",
      "Initial obs shape: (270,) dtype: float32\n",
      "step=0, reward=0.0, done=False\n",
      "step=1000, reward=0.01565884944421508, done=True\n",
      "step=2000, reward=0.0, done=False\n",
      "step=3000, reward=0.01565884944421508, done=True\n",
      "step=4000, reward=0.0, done=False\n",
      "step=5000, reward=0.011511203715304525, done=True\n",
      "step=6000, reward=0.008492195446562437, done=True\n",
      "step=7000, reward=0.0, done=False\n",
      "step=8000, reward=0.0, done=False\n",
      "step=9000, reward=0.01565884944421508, done=True\n",
      "Random roll-out finished without crash.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
     ]
    }
   ],
   "source": [
    "from pipeline.state_assembler import StateAssembler\n",
    "\n",
    "# removing empty items\n",
    "dataset = dataset.dropna().copy()\n",
    "\n",
    "# # Assemble rolling-window states\n",
    "# assembler = StateAssembler(\n",
    "#     feature_cols=[c for c in dataset.columns if c != \"price\"],\n",
    "#     window_size=30\n",
    "# )\n",
    "# state_df = assembler.assemble(dataset)\n",
    "# # print(state_df.shape)\n",
    "# # print(state_df.tail())\n",
    "# # 3. Align prices by using the *same index* as state_df\n",
    "# prices = dataset.loc[state_df.index, \"price\"]\n",
    "\n",
    "# print(\"state_df shape:\", state_df.shape)\n",
    "# print(\"prices shape:\", prices.shape)\n",
    "from envs.buy_env import BuyEnv\n",
    "# from state_assembler import StateAssembler\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you’ve already built `dataset` with your indicators + price\n",
    "feature_cols = [\"return_1d\", \"rsi14\", \"macd_diff\", \"bb_b\",\n",
    "                \"atr14\", \"roc10\", \"obv\", \"mfi14\", \"willr14\"]\n",
    "\n",
    "assembler = StateAssembler(feature_cols=feature_cols, window_size=30)\n",
    "state_df = assembler.assemble(dataset)\n",
    "\n",
    "# Align prices index with state_df\n",
    "prices = dataset.loc[state_df.index, \"price\"]\n",
    "\n",
    "env = BuyEnv(state_df, prices, horizon=5, transaction_cost=0.001)\n",
    "\n",
    "obs = env.reset()\n",
    "print(\"Initial obs shape:\", obs.shape, \"dtype:\", obs.dtype)\n",
    "\n",
    "for step in range(10_000):\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    if step % 1000 == 0:\n",
    "        print(f\"step={step}, reward={reward}, done={done}\")\n",
    "    if done:\n",
    "        obs = env.reset()\n",
    "\n",
    "print(\"Random roll-out finished without crash.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a0e495",
   "metadata": {},
   "source": [
    "## Buy Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64d1f3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- ENV DEBUG ----\n",
      "states shape: (1194, 270) dtype: float64\n",
      "prices shape: (1194,) dtype: float64\n",
      "nan in states: 0\n",
      "nan in prices: 0\n",
      "--------------------\n",
      "Initial state shape: (270,)\n",
      "step=0, action=0, reward=0.0000, done=False, info={'t': 1, 'price': 47.02928161621094}\n",
      "step=1, action=1, reward=0.0085, done=True, info={'t': 2, 'price': 47.76933670043945}\n"
     ]
    }
   ],
   "source": [
    "from envs.buy_env import BuyEnv\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# # 3) Align prices\n",
    "\n",
    "# dataset = dataset.dropna().copy()\n",
    "# prices = dataset[\"price\"].copy()\n",
    "# states = dataset.drop(columns=[\"price\"]).copy()\n",
    "\n",
    "# price_aligned = dataset.loc[state_df.index, \"price\"]\n",
    "\n",
    "# print(\"state_df shape:\", state_df.shape)\n",
    "# print(\"prices shape:\", prices.shape)\n",
    "\n",
    "# print(\"NaNs in state_df:\", np.isnan(state_df.values).sum())\n",
    "# print(\"NaNs in prices:\", np.isnan(prices.values).sum())\n",
    "\n",
    "\n",
    "# 4) Create environment\n",
    "# env = BuyEnv(state_df, price_aligned, horizon=5, transaction_cost=0.001)\n",
    "env = BuyEnv(state_df, prices, horizon=5, transaction_cost=0.001)\n",
    "\n",
    "# 5) Smoke test\n",
    "obs = env.reset()\n",
    "print(\"Initial state shape:\", obs.shape)\n",
    "\n",
    "for step in range(5):\n",
    "    action = env.action_space.sample()  # random action\n",
    "    next_obs, reward, done, info = env.step(action)\n",
    "    print(f\"step={step}, action={action}, reward={reward:.4f}, done={done}, info={info}\")\n",
    "    if done:\n",
    "        break\n",
    "\n",
    "# print(\"Initial obs shape:\", obs.shape)\n",
    "\n",
    "# from stable_baselines3 import DQN\n",
    "\n",
    "# model = DQN(\"MlpPolicy\", env, verbose=1)\n",
    "# model.learn(total_timesteps=5_000)\n",
    "\n",
    "# obs = env.reset()\n",
    "# action = model.predict(obs, deterministic=True)[0]\n",
    "# print(\"Greedy action:\", action)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554169c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from stable_baselines3 import DQN\n",
    "# from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "# # # Rebuild env exactly as above\n",
    "# # feature_cols = [\"return_1d\", \"rsi14\", \"macd_diff\", \"bb_b\",\n",
    "# #                 \"atr14\", \"roc10\", \"obv\", \"mfi14\", \"willr14\"]\n",
    "# # assembler = StateAssembler(feature_cols=feature_cols, window_size=30)\n",
    "# # state_df = assembler.assemble(dataset)\n",
    "# # prices = dataset.loc[state_df.index, \"price\"]\n",
    "\n",
    "# # env = BuyEnv(state_df, prices, horizon=5, transaction_cost=0.001)\n",
    "\n",
    "# # Wrap explicitly in DummyVecEnv (SB3 does this internally, but we make it explicit)\n",
    "# vec_env = DummyVecEnv([lambda: env])\n",
    "\n",
    "# model = DQN(\n",
    "#     \"MlpPolicy\",\n",
    "#     vec_env,\n",
    "#     verbose=1,\n",
    "#     learning_rate=1e-4,\n",
    "#     buffer_size=5_000,\n",
    "#     batch_size=32,\n",
    "#     train_freq=1,\n",
    "#     gradient_steps=1,\n",
    "#     exploration_fraction=0.1,\n",
    "#     exploration_final_eps=0.01,\n",
    "#     target_update_interval=500,\n",
    "# )\n",
    "\n",
    "# model.learn(total_timesteps=5_000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b37029",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m set_seeds(\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Make sure we run from project root\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m os\u001b[38;5;241m.\u001b[39mchdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(\u001b[38;5;18;43m__file__\u001b[39;49m)))\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# 1) create trainer for one ticker (e.g. AAPL)\u001b[39;00m\n\u001b[1;32m     26\u001b[0m trainer \u001b[38;5;241m=\u001b[39m BuyAgentTrainer(\n\u001b[1;32m     27\u001b[0m     cfg_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig/data_config.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     28\u001b[0m     ticker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAAPL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     transaction_cost\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m,\n\u001b[1;32m     32\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "# scripts/train_buy_ddqn.py\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from agents.buy_agent_ddqn import BuyAgentTrainer\n",
    "\n",
    "def set_seeds(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Just to be safe / reproducible\n",
    "    set_seeds(42)\n",
    "\n",
    "    # Make sure we run from project root\n",
    "    os.chdir(os.path.dirname(os.path.dirname(__file__)))\n",
    "\n",
    "    # 1) create trainer for one ticker (e.g. AAPL)\n",
    "    trainer = BuyAgentTrainer(\n",
    "        cfg_path=\"config/data_config.yaml\",\n",
    "        ticker=\"AAPL\",\n",
    "        window_size=30,\n",
    "        horizon=5,\n",
    "        transaction_cost=0.001,\n",
    "    )\n",
    "\n",
    "    # 2) quick training run (PoC)\n",
    "    #    start small (e.g. 50 episodes) to make sure everything works\n",
    "    rewards = trainer.train(\n",
    "        n_episodes=50,\n",
    "        max_steps_per_episode=None,  # let env end naturally\n",
    "        warmup_steps=500,\n",
    "    )\n",
    "\n",
    "    print(\"Last 10 episode rewards:\", rewards[-10:])\n",
    "\n",
    "    # 3) run greedy policy once to see how it behaves\n",
    "    greedy_policy = trainer.make_greedy_policy()\n",
    "    total_reward, steps = greedy_policy(trainer.env)\n",
    "    print(f\"Greedy run: total_reward={total_reward:.4f}, steps={steps}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0c66df",
   "metadata": {},
   "source": [
    "## Training agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76062458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from agents.buy_agent_ddqn import BuyAgentDDQN\n",
    "\n",
    "# # Reuse env from previous block\n",
    "# buy_agent = BuyAgentDDQN(env, learning_rate=1e-4, gamma=0.99)\n",
    "\n",
    "# # Short training run just to validate everything works\n",
    "# buy_agent.train(timesteps=10_000)\n",
    "\n",
    "# # Save model\n",
    "# buy_agent.save(\"results/models/buy_agent_aapl_ddqn\")\n",
    "\n",
    "# # Test one greedy decision\n",
    "# obs = env.reset()\n",
    "# action = buy_agent.act(obs)\n",
    "# print(\"Greedy action at start:\", action)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.14",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
