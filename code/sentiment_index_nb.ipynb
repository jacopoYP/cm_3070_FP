{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2314136",
   "metadata": {},
   "source": [
    "# Sentiment Index Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a59fffc",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6ac359",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install finnhub-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1d5921",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import hashlib\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a9cbcf",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd99015",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYMBOL = \"AAPL\"\n",
    "START = \"2024-01-01\"\n",
    "END   = \"2024-06-30\"\n",
    "\n",
    "# FINNHUB_API_KEY = os.getenv(\"FINNHUB_API_KEY\", \"\").strip()\n",
    "FINNHUB_API_KEY = \"d5lbg61r01qgquflgn9gd5lbg61r01qgquflgna0\"\n",
    "assert FINNHUB_API_KEY, \"Set FINNHUB_API_KEY as an environment variable first.\"\n",
    "\n",
    "CACHE_DIR = \"cache/finnhub\"\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "\n",
    "MIN_INTERVAL_S = 1.2   # safe pacing for free tier\n",
    "TIMEOUT_S = 20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc0f935",
   "metadata": {},
   "source": [
    "## Finnhub client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b76466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @dataclass\n",
    "# class FinnhubClient:\n",
    "#     api_key: str\n",
    "#     cache_dir: str = CACHE_DIR\n",
    "#     min_interval_s: float = MIN_INTERVAL_S\n",
    "#     timeout_s: float = TIMEOUT_S\n",
    "\n",
    "#     def __post_init__(self):\n",
    "#         self._last_call_ts = 0.0\n",
    "\n",
    "#     def _sleep_if_needed(self):\n",
    "#         dt = time.time() - self._last_call_ts\n",
    "#         if dt < self.min_interval_s:\n",
    "#             time.sleep(self.min_interval_s - dt)\n",
    "\n",
    "#     def _cache_path(self, url: str, params: Dict[str, Any]) -> str:\n",
    "#         raw = url + \"?\" + \"&\".join(f\"{k}={params[k]}\" for k in sorted(params.keys()))\n",
    "#         h = hashlib.sha256(raw.encode(\"utf-8\")).hexdigest()[:24]\n",
    "#         return os.path.join(self.cache_dir, f\"{h}.json\")\n",
    "\n",
    "#     def _get_json(self, url: str, params: Dict[str, Any], use_cache: bool = True) -> Any:\n",
    "#         params = dict(params)\n",
    "#         params[\"token\"] = self.api_key\n",
    "\n",
    "#         cache_path = self._cache_path(url, params)\n",
    "#         if use_cache and os.path.exists(cache_path):\n",
    "#             with open(cache_path, \"r\", encoding=\"utf-8\") as f:\n",
    "#                 return json.load(f)\n",
    "\n",
    "#         self._sleep_if_needed()\n",
    "#         r = requests.get(url, params=params, timeout=self.timeout_s)\n",
    "#         self._last_call_ts = time.time()\n",
    "\n",
    "#         if r.status_code == 429:\n",
    "#             raise RuntimeError(\"Finnhub rate limit hit (429). Reduce calls or rely on cache.\")\n",
    "\n",
    "#         r.raise_for_status()\n",
    "#         data = r.json()\n",
    "\n",
    "#         if use_cache:\n",
    "#             with open(cache_path, \"w\", encoding=\"utf-8\") as f:\n",
    "#                 json.dump(data, f)\n",
    "\n",
    "#         return data\n",
    "\n",
    "#     def company_news(self, symbol: str, date_from: str, date_to: str) -> List[Dict[str, Any]]:\n",
    "#         url = \"https://finnhub.io/api/v1/company-news\"\n",
    "#         params = {\"symbol\": symbol, \"from\": date_from, \"to\": date_to}\n",
    "#         print(\"params: \", params)\n",
    "#         data = self._get_json(url, params=params, use_cache=True)\n",
    "#         print(\"data: \", data)\n",
    "#         return list(data) if isinstance(data, list) else []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384ab7ef",
   "metadata": {},
   "source": [
    "## Sentiment index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c17888e",
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_WORDS = {\n",
    "    \"beat\", \"beats\", \"growth\", \"surge\", \"record\", \"profit\", \"profits\", \"upgrade\",\n",
    "    \"strong\", \"bull\", \"bullish\", \"outperform\", \"rally\", \"upside\", \"win\", \"wins\"\n",
    "}\n",
    "NEG_WORDS = {\n",
    "    \"miss\", \"misses\", \"drop\", \"falls\", \"plunge\", \"loss\", \"losses\", \"downgrade\",\n",
    "    \"weak\", \"bear\", \"bearish\", \"underperform\", \"crash\", \"downside\", \"lawsuit\"\n",
    "}\n",
    "\n",
    "def _tokenize(text: str) -> List[str]:\n",
    "    if not text:\n",
    "        return []\n",
    "    t = \"\".join(ch.lower() if ch.isalnum() else \" \" for ch in text)\n",
    "    return [w for w in t.split() if len(w) >= 2]\n",
    "\n",
    "def headline_polarity(headline: str) -> float:\n",
    "    toks = _tokenize(headline)\n",
    "    if not toks:\n",
    "        return 0.0\n",
    "    pos = sum(1 for w in toks if w in POS_WORDS)\n",
    "    neg = sum(1 for w in toks if w in NEG_WORDS)\n",
    "    return float((pos - neg) / (pos + neg + 1e-9))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac05d56",
   "metadata": {},
   "source": [
    "## Daily prices (yFinance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a699e387",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = yf.download(SYMBOL, start=START, end=END, interval=\"1d\", auto_adjust=True, progress=False)\n",
    "df = df.dropna().copy()\n",
    "df.index = pd.to_datetime(df.index).tz_localize(None)  # keep dates naive\n",
    "df[\"date\"] = df.index.strftime(\"%Y-%m-%d\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7b6858",
   "metadata": {},
   "source": [
    "## Raw Sentiment index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61d6d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = FinnhubClient(api_key=FINNHUB_API_KEY)\n",
    "\n",
    "from data.finnhub_api import FinnhubClient\n",
    "\n",
    "client = FinnhubClient(api_key=FINNHUB_API_KEY)\n",
    "\n",
    "news = client.company_news_range(\n",
    "    symbol=\"AAPL\",\n",
    "    date_from=\"2024-01-02\",\n",
    "    date_to=\"2025-01-02\"\n",
    ")\n",
    "\n",
    "len(news), news[:2]\n",
    "\n",
    "\n",
    "# dates = df[\"date\"].tolist()\n",
    "# raw = np.zeros(len(dates), dtype=np.float32)\n",
    "# n_news = np.zeros(len(dates), dtype=np.int32)\n",
    "# print(\"dates\")\n",
    "# print(dates)\n",
    "\n",
    "# for i, d in enumerate(dates):\n",
    "#     news = client.company_news(SYMBOL, \"2020-06-01\", \"2020-06-10\")\n",
    "#     # news = client.company_news(SYMBOL, _from=\"2020-06-01\", to=\"2020-06-10\")\n",
    "\n",
    "#     # print(\"news\")\n",
    "#     # print(news)\n",
    "#     n_news[i] = len(news)\n",
    "#     if not news:\n",
    "#         raw[i] = 0.0\n",
    "#         continue\n",
    "#     pols = [headline_polarity(item.get(\"headline\") or \"\") for item in news]\n",
    "#     raw[i] = float(np.mean(pols)) if pols else 0.0\n",
    "\n",
    "# df[\"news_count\"] = n_news\n",
    "# df[\"sent_raw\"] = raw\n",
    "# df[[\"Close\", \"news_count\", \"sent_raw\"]].head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba29a78",
   "metadata": {},
   "source": [
    "## Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6159ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ewma(x: np.ndarray, alpha: float = 0.2) -> np.ndarray:\n",
    "    out = np.zeros_like(x, dtype=np.float32)\n",
    "    m = 0.0\n",
    "    for i in range(len(x)):\n",
    "        m = alpha * float(x[i]) + (1.0 - alpha) * m\n",
    "        out[i] = m\n",
    "    return out\n",
    "\n",
    "def rolling_z(x: np.ndarray, window: int = 60, clip: float = 3.0) -> np.ndarray:\n",
    "    out = np.zeros_like(x, dtype=np.float32)\n",
    "    for i in range(len(x)):\n",
    "        lo = max(0, i - window + 1)\n",
    "        win = x[lo:i+1]\n",
    "        mu = float(np.mean(win))\n",
    "        sd = float(np.std(win)) + 1e-6\n",
    "        z = (float(x[i]) - mu) / sd\n",
    "        if clip is not None:\n",
    "            z = float(np.clip(z, -clip, clip))\n",
    "        out[i] = z\n",
    "    return out\n",
    "\n",
    "df[\"sent_ewma\"] = ewma(df[\"sent_raw\"].values, alpha=0.2)\n",
    "df[\"sent_z\"] = rolling_z(df[\"sent_ewma\"].values, window=60, clip=3.0)\n",
    "\n",
    "df[[\"news_count\",\"sent_raw\",\"sent_ewma\",\"sent_z\"]].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323e5946",
   "metadata": {},
   "source": [
    "## Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ae8947",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Days:\", len(df))\n",
    "print(\"Days with news:\", int((df[\"news_count\"] > 0).sum()))\n",
    "print(\"Raw sentiment min/mean/max:\", float(df[\"sent_raw\"].min()), float(df[\"sent_raw\"].mean()), float(df[\"sent_raw\"].max()))\n",
    "print(\"Z sentiment min/mean/max:\", float(df[\"sent_z\"].min()), float(df[\"sent_z\"].mean()), float(df[\"sent_z\"].max()))\n",
    "\n",
    "# If 'Days with news' is too low, widen date range or switch API later.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ebeb8b",
   "metadata": {},
   "source": [
    "## Testing Alpha Vanatage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ae8a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for:  {'function': 'NEWS_SENTIMENT', 'tickers': 'AAPL', 'time_from': '20230101T0000', 'limit': '1000', 'sort': 'LATEST', 'apikey': 'FYFJWZUN7XRMOHJT'}\n",
      "Fetching data for:  {'function': 'NEWS_SENTIMENT', 'tickers': 'AAPL', 'time_from': '20230101T0000', 'limit': '1000', 'sort': 'LATEST', 'apikey': 'FYFJWZUN7XRMOHJT'}\n",
      "Fetching data for:  {'function': 'NEWS_SENTIMENT', 'tickers': 'AAPL', 'time_from': '20230101T0000', 'limit': '1000', 'sort': 'LATEST', 'apikey': 'FYFJWZUN7XRMOHJT'}\n",
      "Fetching data for:  {'function': 'NEWS_SENTIMENT', 'tickers': 'AAPL', 'time_from': '20230101T0000', 'limit': '1000', 'sort': 'LATEST', 'apikey': 'FYFJWZUN7XRMOHJT'}\n",
      "Fetching data for:  {'function': 'NEWS_SENTIMENT', 'tickers': 'AMZN', 'time_from': '20230101T0000', 'limit': '1000', 'sort': 'LATEST', 'apikey': 'FYFJWZUN7XRMOHJT'}\n",
      "Fetching data for:  {'function': 'NEWS_SENTIMENT', 'tickers': 'AMZN', 'time_from': '20230101T0000', 'limit': '1000', 'sort': 'LATEST', 'apikey': 'FYFJWZUN7XRMOHJT'}\n",
      "Fetching data for:  {'function': 'NEWS_SENTIMENT', 'tickers': 'AMZN', 'time_from': '20230101T0000', 'limit': '1000', 'sort': 'LATEST', 'apikey': 'FYFJWZUN7XRMOHJT'}\n",
      "Fetching data for:  {'function': 'NEWS_SENTIMENT', 'tickers': 'AMZN', 'time_from': '20230101T0000', 'limit': '1000', 'sort': 'LATEST', 'apikey': 'FYFJWZUN7XRMOHJT'}\n",
      "Fetching data for:  {'function': 'NEWS_SENTIMENT', 'tickers': 'MSFT', 'time_from': '20230101T0000', 'limit': '1000', 'sort': 'LATEST', 'apikey': 'FYFJWZUN7XRMOHJT'}\n",
      "Fetching data for:  {'function': 'NEWS_SENTIMENT', 'tickers': 'MSFT', 'time_from': '20230101T0000', 'limit': '1000', 'sort': 'LATEST', 'apikey': 'FYFJWZUN7XRMOHJT'}\n",
      "Fetching data for:  {'function': 'NEWS_SENTIMENT', 'tickers': 'MSFT', 'time_from': '20230101T0000', 'limit': '1000', 'sort': 'LATEST', 'apikey': 'FYFJWZUN7XRMOHJT'}\n",
      "Fetching data for:  {'function': 'NEWS_SENTIMENT', 'tickers': 'MSFT', 'time_from': '20230101T0000', 'limit': '1000', 'sort': 'LATEST', 'apikey': 'FYFJWZUN7XRMOHJT'}\n",
      "Fetching data for:  {'function': 'NEWS_SENTIMENT', 'tickers': 'GOOGL', 'time_from': '20230101T0000', 'limit': '1000', 'sort': 'LATEST', 'apikey': 'FYFJWZUN7XRMOHJT'}\n",
      "Fetching data for:  {'function': 'NEWS_SENTIMENT', 'tickers': 'GOOGL', 'time_from': '20230101T0000', 'limit': '1000', 'sort': 'LATEST', 'apikey': 'FYFJWZUN7XRMOHJT'}\n",
      "Fetching data for:  {'function': 'NEWS_SENTIMENT', 'tickers': 'GOOGL', 'time_from': '20230101T0000', 'limit': '1000', 'sort': 'LATEST', 'apikey': 'FYFJWZUN7XRMOHJT'}\n",
      "Fetching data for:  {'function': 'NEWS_SENTIMENT', 'tickers': 'GOOGL', 'time_from': '20230101T0000', 'limit': '1000', 'sort': 'LATEST', 'apikey': 'FYFJWZUN7XRMOHJT'}\n",
      "Fetching data for:  {'function': 'NEWS_SENTIMENT', 'tickers': 'META', 'time_from': '20230101T0000', 'limit': '1000', 'sort': 'LATEST', 'apikey': 'FYFJWZUN7XRMOHJT'}\n",
      "Fetching data for:  {'function': 'NEWS_SENTIMENT', 'tickers': 'META', 'time_from': '20230101T0000', 'limit': '1000', 'sort': 'LATEST', 'apikey': 'FYFJWZUN7XRMOHJT'}\n",
      "Fetching data for:  {'function': 'NEWS_SENTIMENT', 'tickers': 'META', 'time_from': '20230101T0000', 'limit': '1000', 'sort': 'LATEST', 'apikey': 'FYFJWZUN7XRMOHJT'}\n",
      "Fetching data for:  {'function': 'NEWS_SENTIMENT', 'tickers': 'META', 'time_from': '20230101T0000', 'limit': '1000', 'sort': 'LATEST', 'apikey': 'FYFJWZUN7XRMOHJT'}\n"
     ]
    }
   ],
   "source": [
    "from data.finnhub_api import AlphaVantageNewsClient\n",
    "\n",
    "client = AlphaVantageNewsClient(\n",
    "    api_key=\"FYFJWZUN7XRMOHJT\",\n",
    "    cache_dir=\"cache/alphavantage_news\",\n",
    ")\n",
    "\n",
    "tickers = [\"AAPL\", \"AMZN\", \"MSFT\", \"GOOGL\", \"META\"]\n",
    "start_date = \"2018-01-01\"\n",
    "end_date = \"2024-01-01\"\n",
    "\n",
    "all_news = {}\n",
    "for t in tickers:\n",
    "    all_news[t] = client.fetch_news(t, start_date, end_date, limit=1000, use_cache=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.14",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
