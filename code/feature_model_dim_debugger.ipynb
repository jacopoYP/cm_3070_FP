{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad170bff",
   "metadata": {},
   "source": [
    "# Feature/Model Dimension Debugger\n",
    "This notebook helps you find why runtime state vectors have length 15 while your trained model expects 18.\n",
    "\n",
    "It checks:\n",
    "- The **expected input dim** from your saved buy/sell PyTorch checkpoints\n",
    "- The **actual feature dim** in your built dataset (`features.npy` / optional `features.csv`)\n",
    "- Per-ticker feature dims (if you have per-ticker saved CSV)\n",
    "- The **API-time state builder** output length (if you point it to the function)\n",
    "\n",
    "**Edit the paths in the first cell** to match your repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6f31882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: /Users/jacopo/Documents/uni/FinalProject/cm_3070_FP/code\n",
      "DATA_DIR: /Users/jacopo/Documents/uni/FinalProject/cm_3070_FP/code/data\n"
     ]
    }
   ],
   "source": [
    "# --- Paths: edit these ---\n",
    "PROJECT_ROOT = r\"/Users/jacopo/Documents/uni/FinalProject/cm_3070_FP/code\"\n",
    "DATA_DIR     = r\"/Users/jacopo/Documents/uni/FinalProject/cm_3070_FP/code/data\"  # where features.npy lives\n",
    "BUY_CKPT     = r\"/Users/jacopo/Documents/uni/FinalProject/cm_3070_FP/code/models/buy_agent.pt\"\n",
    "SELL_CKPT    = r\"/Users/jacopo/Documents/uni/FinalProject/cm_3070_FP/code/models/sell_agent.pt\"\n",
    "\n",
    "# Optional: if you saved CSV during build_features (--save_csv)\n",
    "FEATURES_CSV = None  # e.g. r\"/.../data/features.csv\"\n",
    "META_CSV     = None  # e.g. r\"/.../data/row_meta.csv\"\n",
    "\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"DATA_DIR:\", DATA_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a11c4f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint buy_agent.pt appears to be a raw object/state_dict.\n",
      "Checkpoint sell_agent.pt appears to be a raw object/state_dict.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cfg': {'gamma': 0.99,\n",
       "  'lr': 0.001,\n",
       "  'batch_size': 64,\n",
       "  'buffer_size': 200000,\n",
       "  'target_update_freq': 500,\n",
       "  'epsilon_start': 1.0,\n",
       "  'epsilon_end': 0.05,\n",
       "  'epsilon_decay_steps': 48000,\n",
       "  'state_dim': 18,\n",
       "  'n_actions': 2},\n",
       " 'state_dict': OrderedDict([('net.0.weight',\n",
       "               tensor([[-0.0346, -0.1603, -0.1516,  ..., -0.2059, -0.7193, -0.1594],\n",
       "                       [-0.0152, -0.1232,  0.1241,  ..., -0.4886,  0.1563,  0.2725],\n",
       "                       [-0.0945,  0.2238,  0.0696,  ...,  0.2968, -0.2249, -0.1018],\n",
       "                       ...,\n",
       "                       [-0.0203, -0.1697,  0.3470,  ...,  0.4655, -0.3510,  0.0058],\n",
       "                       [ 0.0804,  0.1480, -0.2966,  ...,  1.0250, -0.3420, -0.2935],\n",
       "                       [-0.2918, -0.2472,  0.0630,  ..., -0.4796,  0.0973, -0.1121]])),\n",
       "              ('net.0.bias',\n",
       "               tensor([-0.2649,  0.1101, -0.1570, -0.0650, -0.1043,  0.2918, -0.0434,  0.0820,\n",
       "                        0.1510, -0.2430, -0.6842, -0.3728,  0.0143, -0.1137,  0.0526, -0.0556,\n",
       "                       -0.2817, -0.1912, -0.1222, -0.2723,  0.1650, -0.3857, -0.3156,  0.0657,\n",
       "                       -0.5068, -0.4199, -0.1172,  0.0464, -0.1457, -0.0888, -0.0111,  0.0045,\n",
       "                        0.0269, -0.5209, -0.2901, -0.3835, -0.1793,  0.1653, -0.4267,  0.2253,\n",
       "                       -0.5679, -0.0183, -0.2597, -0.3542, -0.1664, -0.0398, -0.3489, -0.3612,\n",
       "                        0.1527, -0.0285, -0.0750, -0.4120, -0.1494, -0.5621, -0.2592, -0.1258,\n",
       "                       -0.3325,  0.0335,  0.1059, -0.0768,  0.0207, -0.1808, -0.5242, -0.3088,\n",
       "                       -0.0831, -0.3573, -0.1558, -0.2612,  0.1108, -0.0357, -0.0745, -0.2883,\n",
       "                       -0.3722, -0.5618, -0.2069,  0.0767, -0.1507, -0.0030, -0.2009, -0.1255,\n",
       "                        0.0314, -0.1868, -0.2532,  0.1329, -0.0824,  0.1827,  0.0877, -0.2909,\n",
       "                       -0.0995, -0.0547, -0.0669, -0.2542, -0.5548, -0.0333, -0.0854, -0.0751,\n",
       "                        0.0541, -0.5241,  0.0491, -0.0150,  0.2743, -0.0155, -0.1772, -0.0905,\n",
       "                        0.0881, -0.1072, -0.2564, -0.3828, -0.5208,  0.2000, -0.1093,  0.1418,\n",
       "                       -0.1093, -0.1702,  0.2211, -0.0050,  0.0124, -0.3191, -0.4688, -0.0600,\n",
       "                       -0.3610, -0.2839, -0.3181, -0.1893, -0.0372, -0.1439,  0.0718, -0.0170])),\n",
       "              ('net.2.weight',\n",
       "               tensor([[ 0.0473, -0.1699,  0.1464,  ..., -0.1684,  0.1045, -0.0942],\n",
       "                       [-0.7688,  0.2313, -0.1478,  ..., -0.3864,  0.0158, -0.1261],\n",
       "                       [-0.1035, -0.1277, -0.6901,  ..., -0.1341, -0.4937, -0.1908],\n",
       "                       ...,\n",
       "                       [-0.3872, -1.0131, -0.1446,  ..., -0.3326, -0.3416,  0.1177],\n",
       "                       [-0.0883, -0.0186, -0.1308,  ..., -0.0250, -0.1576, -0.1766],\n",
       "                       [ 0.2318, -0.5771, -0.1158,  ...,  0.1896, -0.6495, -0.3999]])),\n",
       "              ('net.2.bias',\n",
       "               tensor([-0.2569,  0.1191, -0.2609,  0.0349, -0.0471, -0.0115,  0.0400, -0.1115,\n",
       "                       -0.2097, -0.2873, -0.1246, -0.1761, -0.3335, -0.2447, -0.2837, -0.3355,\n",
       "                       -0.0704,  0.1338, -0.2732, -0.0505,  0.1825, -0.3394, -0.0165, -0.1135,\n",
       "                       -0.0470, -0.0227,  0.0888, -0.0266, -0.0656, -0.1496, -0.3306, -0.0154,\n",
       "                        0.2116,  0.0400, -0.2688,  0.0680, -0.1522,  0.1506, -0.0405,  0.3702,\n",
       "                       -0.1179, -0.1677,  0.0318, -0.0084,  0.0499,  0.0347, -0.1724,  0.0483,\n",
       "                       -0.0387,  0.1755,  0.0040, -0.3453,  0.0175, -0.0984, -0.1405, -0.0148,\n",
       "                        0.1514,  0.0300, -0.3929,  0.1512, -0.2485, -0.1575, -0.1781, -0.0461,\n",
       "                       -0.2406, -0.2077, -0.1500, -0.1114, -0.3772, -0.1208, -0.1438, -0.0717,\n",
       "                       -0.1600, -0.0770, -0.2157, -0.0436, -0.3029, -0.1180, -0.0784, -0.1265,\n",
       "                        0.0751,  0.0366, -0.1859, -0.3009, -0.2091, -0.2605,  0.0573,  0.2036,\n",
       "                       -0.0710,  0.0124, -0.3843,  0.0939,  0.0058, -0.1704, -0.2339,  0.0288,\n",
       "                       -0.1048,  0.1555, -0.1630,  0.1854,  0.0965, -0.0396, -0.0348,  0.0681,\n",
       "                       -0.1255, -0.2440, -0.0805, -0.1890,  0.0287, -0.1270, -0.1263, -0.3141,\n",
       "                       -0.0463,  0.0114, -0.2609,  0.0060, -0.1233, -0.0628, -0.1975, -0.1085,\n",
       "                        0.1430, -0.2453, -0.4220, -0.0085, -0.2380, -0.3135, -0.0576, -0.3935])),\n",
       "              ('net.4.weight',\n",
       "               tensor([[ 7.4396e-02,  5.4774e-03,  3.9589e-01,  2.8642e-02,  3.5619e-04,\n",
       "                        -1.6419e-01, -8.1495e-03,  2.5690e-02,  5.7049e-02,  3.7363e-02,\n",
       "                         4.6607e-03,  1.2177e-01,  4.3059e-02,  1.1007e-01, -8.5467e-03,\n",
       "                         5.6369e-02, -5.5893e-02,  5.5073e-04, -3.3708e-02, -4.4110e-03,\n",
       "                        -1.6325e-02,  7.4338e-02,  9.2992e-02, -6.9717e-02, -5.3680e-02,\n",
       "                        -3.6455e-02, -1.7324e-02,  3.0609e-03,  1.6178e-01, -3.5938e-02,\n",
       "                         1.1536e-01, -5.4849e-03, -2.0569e-03, -4.4672e-03, -2.2923e-02,\n",
       "                         2.1956e-02,  3.7297e-01,  1.1820e-03,  1.7228e-01, -2.2209e-02,\n",
       "                         9.6030e-02, -3.0131e-02,  8.9401e-02, -2.4995e-02, -4.1379e-02,\n",
       "                         5.6612e-03,  2.1042e-03,  1.2515e-02,  1.1808e-02, -3.7734e-03,\n",
       "                        -2.8312e-03,  6.7228e-02, -4.7352e-03,  2.8055e-01,  1.9513e-01,\n",
       "                        -2.2607e-02, -5.0007e-03, -1.5272e-03,  1.1547e-01, -9.5385e-03,\n",
       "                         5.2512e-02, -1.1503e-02, -2.7069e-02,  6.7426e-02,  7.4302e-02,\n",
       "                        -4.0733e-03,  4.7413e-02, -3.6364e-02,  1.2088e-01,  7.0458e-02,\n",
       "                        -3.0497e-02,  8.9758e-02, -7.1737e-04, -6.1844e-02,  1.2595e-01,\n",
       "                         2.3081e-02,  1.3505e-02,  3.3670e-02,  2.5938e-02,  5.3018e-02,\n",
       "                         7.6216e-04, -1.0228e-03,  3.9708e-02,  2.2766e-02,  8.3960e-03,\n",
       "                         2.8424e-03, -3.3650e-03, -4.9182e-02,  6.3145e-02,  5.1890e-03,\n",
       "                         1.0107e-01, -1.2295e-03, -2.2760e-03, -3.2964e-02,  2.0588e-01,\n",
       "                         2.0677e-01,  4.8905e-02,  3.8479e-03,  9.8416e-02, -1.9196e-03,\n",
       "                         3.0944e-02,  2.3759e-01,  5.1933e-03,  1.3217e-02,  6.1828e-02,\n",
       "                         7.8412e-02, -5.6458e-02,  6.1077e-02,  4.0757e-02,  2.5434e-02,\n",
       "                        -5.8155e-03,  1.2943e-01,  1.8734e-01,  2.0015e-01,  4.2722e-03,\n",
       "                         8.2351e-03,  2.2415e-01,  1.1596e-01, -5.9423e-02, -2.2147e-02,\n",
       "                        -1.6279e-02,  2.6721e-02,  9.4967e-03, -1.4014e-03,  3.1976e-01,\n",
       "                         1.5004e-01,  9.4308e-02,  9.8202e-02],\n",
       "                       [ 4.2024e-02, -1.0504e-01,  3.8905e-01, -9.3458e-02, -1.0814e-01,\n",
       "                        -2.3924e-01, -5.8839e-02, -2.4208e-02,  7.8076e-02,  6.6768e-02,\n",
       "                        -9.8530e-02,  1.5809e-01,  5.3449e-02,  1.1102e-01, -9.1904e-02,\n",
       "                         5.3564e-02, -1.4008e-02,  1.2392e-01, -3.6877e-02, -9.9807e-02,\n",
       "                        -5.1229e-01,  5.5592e-02,  1.1261e-01, -1.1120e-01, -6.2790e-02,\n",
       "                         1.2088e-01, -1.4732e-01, -1.2429e-01,  1.5709e-01,  3.9789e-02,\n",
       "                         5.0989e-02, -1.0938e-01, -4.7175e-01, -4.4236e-02,  9.4707e-02,\n",
       "                        -8.4001e-02,  3.5060e-01, -1.0353e-01,  1.9510e-01, -1.9141e-02,\n",
       "                         1.1399e-01, -4.4446e-02,  1.4630e-01, -6.4428e-02, -1.8695e-02,\n",
       "                        -1.3506e-01, -1.0177e-01,  7.1106e-02, -2.3467e-01, -3.0132e-01,\n",
       "                        -5.9877e-02,  7.1750e-02, -1.3558e-01,  2.4435e-01,  2.0994e-01,\n",
       "                        -1.9473e-01, -1.6041e-01, -7.7481e-02,  9.5508e-02, -1.0852e-01,\n",
       "                         4.8048e-02, -1.0222e-01, -9.6576e-02,  7.7519e-02,  6.0465e-02,\n",
       "                        -1.4344e-02,  1.3243e-01, -2.6124e-01,  1.3246e-01, -2.8910e-02,\n",
       "                         2.1876e-02,  1.0162e-01, -1.0330e-01, -3.9729e-02, -1.2620e-01,\n",
       "                         7.6706e-02,  1.0109e-01,  4.1924e-02, -1.8674e-01,  6.9220e-02,\n",
       "                        -3.3530e-01, -8.8270e-02,  6.3917e-02, -5.8419e-03, -1.6036e-01,\n",
       "                         8.0675e-02, -2.7665e-01, -2.0397e-01,  7.8132e-02, -1.0238e-01,\n",
       "                         2.7239e-02, -1.5435e-01, -1.0516e-01, -1.0702e-04,  1.8801e-01,\n",
       "                         2.0944e-01,  1.0752e-01, -4.4847e-02,  1.0493e-01, -1.0617e-01,\n",
       "                         1.7241e-01,  2.3124e-01, -5.2183e-02,  1.1133e-01,  6.1736e-02,\n",
       "                         8.9997e-02, -7.5582e-02,  9.8419e-02,  1.3884e-01,  8.4817e-02,\n",
       "                        -2.4005e-02,  1.3142e-01,  1.8270e-01,  1.9038e-01,  3.6894e-02,\n",
       "                        -1.6242e-01,  2.3704e-01,  1.1548e-01, -2.3849e-04, -1.6433e-02,\n",
       "                         7.9213e-02,  5.8478e-02,  3.4045e-02, -1.1500e-01,  3.8577e-01,\n",
       "                         1.3209e-01,  1.4585e-02,  1.1984e-01]])),\n",
       "              ('net.4.bias', tensor([0.0190, 0.0233]))]),\n",
       " 'target_state_dict': OrderedDict([('net.0.weight',\n",
       "               tensor([[-0.0412, -0.1663, -0.1432,  ..., -0.2118, -0.7252, -0.1485],\n",
       "                       [-0.0139, -0.1192,  0.1111,  ..., -0.4879,  0.1411,  0.2762],\n",
       "                       [-0.1087,  0.2090,  0.0730,  ...,  0.3090, -0.2340, -0.1174],\n",
       "                       ...,\n",
       "                       [-0.0289, -0.1775,  0.3320,  ...,  0.4582, -0.3527,  0.0047],\n",
       "                       [ 0.0752,  0.1424, -0.2945,  ...,  1.0295, -0.3442, -0.3000],\n",
       "                       [-0.2823, -0.2412,  0.0690,  ..., -0.4824,  0.1148, -0.0822]])),\n",
       "              ('net.0.bias',\n",
       "               tensor([-0.2604,  0.1073, -0.1725, -0.0688, -0.1036,  0.2800, -0.0527,  0.0902,\n",
       "                        0.1647, -0.2455, -0.6660, -0.3727,  0.0149, -0.1211,  0.0497, -0.0399,\n",
       "                       -0.2787, -0.2027, -0.1221, -0.2719,  0.1794, -0.3667, -0.3124,  0.0703,\n",
       "                       -0.5083, -0.4114, -0.1168,  0.0413, -0.1494, -0.0867, -0.0036,  0.0093,\n",
       "                        0.0188, -0.5181, -0.2922, -0.3800, -0.1588,  0.1712, -0.4171,  0.2593,\n",
       "                       -0.5690, -0.0201, -0.2603, -0.3119, -0.1819, -0.0310, -0.3488, -0.3524,\n",
       "                        0.1546, -0.0369, -0.0728, -0.4215, -0.1636, -0.5644, -0.2722, -0.1161,\n",
       "                       -0.3196,  0.0492,  0.1059, -0.0895, -0.0076, -0.1764, -0.5059, -0.3119,\n",
       "                       -0.0859, -0.3746, -0.1534, -0.2549,  0.1086, -0.0380, -0.0704, -0.2833,\n",
       "                       -0.3546, -0.5674, -0.1871,  0.0569, -0.1729, -0.0024, -0.1927, -0.1299,\n",
       "                        0.0315, -0.1918, -0.2401,  0.1417, -0.0983,  0.1553,  0.0954, -0.3012,\n",
       "                       -0.1147, -0.0630, -0.0965, -0.2515, -0.5239, -0.0366, -0.0800, -0.0839,\n",
       "                        0.0544, -0.5237,  0.0552, -0.0143,  0.2796, -0.0253, -0.2014, -0.0955,\n",
       "                        0.0950, -0.1011, -0.2666, -0.3889, -0.5220,  0.1889, -0.1092,  0.1448,\n",
       "                       -0.1182, -0.1737,  0.2050, -0.0152,  0.0262, -0.3111, -0.4684, -0.0531,\n",
       "                       -0.3619, -0.2823, -0.3069, -0.1883, -0.0341, -0.1452,  0.0663,  0.0111])),\n",
       "              ('net.2.weight',\n",
       "               tensor([[ 0.0490, -0.1392,  0.1576,  ..., -0.1814,  0.0878, -0.1011],\n",
       "                       [-0.7375,  0.2466, -0.0996,  ..., -0.3511,  0.0408, -0.1252],\n",
       "                       [-0.1035, -0.1429, -0.6618,  ..., -0.1341, -0.4676, -0.2098],\n",
       "                       ...,\n",
       "                       [-0.3872, -1.0131, -0.1446,  ..., -0.2985, -0.3171,  0.1121],\n",
       "                       [-0.0883, -0.0186, -0.1308,  ..., -0.0250, -0.1576, -0.1766],\n",
       "                       [ 0.2318, -0.5771, -0.1158,  ...,  0.1896, -0.6495, -0.3999]])),\n",
       "              ('net.2.bias',\n",
       "               tensor([-0.2623,  0.1287, -0.2609,  0.0363, -0.0512, -0.0129,  0.0526, -0.1115,\n",
       "                       -0.2144, -0.2746, -0.1088, -0.1864, -0.3269, -0.2514, -0.2827, -0.3214,\n",
       "                       -0.0704,  0.1428, -0.2694, -0.0453,  0.1731, -0.3338, -0.0157, -0.1135,\n",
       "                       -0.0470,  0.0051,  0.0948, -0.0502, -0.0627, -0.1496, -0.3306, -0.0064,\n",
       "                        0.1967,  0.0511, -0.2809,  0.0732, -0.1532,  0.1448, -0.0350,  0.3707,\n",
       "                       -0.1153, -0.1726,  0.0551, -0.0165,  0.0430,  0.0159, -0.1794,  0.0528,\n",
       "                       -0.0510,  0.1595,  0.0018, -0.3421,  0.0203, -0.0998, -0.1445, -0.0134,\n",
       "                        0.1372,  0.0306, -0.3908,  0.1533, -0.2389, -0.1670, -0.1747, -0.0520,\n",
       "                       -0.2318, -0.1971, -0.1356, -0.1184, -0.3681, -0.1208, -0.1438, -0.0690,\n",
       "                       -0.1582, -0.0708, -0.2157, -0.0489, -0.3112, -0.1180, -0.0691, -0.1241,\n",
       "                        0.0675,  0.0232, -0.1830, -0.3009, -0.2030, -0.2599,  0.0641,  0.1947,\n",
       "                       -0.0810,  0.0148, -0.3843,  0.0923,  0.0171, -0.1704, -0.2349,  0.0297,\n",
       "                       -0.1004,  0.1619, -0.1565,  0.1882,  0.0988, -0.0079, -0.0389,  0.0642,\n",
       "                       -0.1335, -0.2381, -0.0740, -0.1818,  0.0139, -0.1270, -0.1188, -0.3149,\n",
       "                       -0.0497,  0.0233, -0.2802, -0.0105, -0.1132, -0.0668, -0.1972, -0.1085,\n",
       "                        0.1572, -0.2326, -0.4220, -0.0121, -0.2418, -0.3133, -0.0576, -0.3935])),\n",
       "              ('net.4.weight',\n",
       "               tensor([[ 7.3567e-02,  3.7036e-03,  3.8548e-01,  6.2059e-05,  2.5746e-03,\n",
       "                        -1.6618e-01, -5.5483e-03,  2.5690e-02,  6.2723e-02,  2.1459e-02,\n",
       "                         7.9358e-03,  1.2484e-01,  3.9785e-02,  1.0280e-01, -5.2509e-03,\n",
       "                         6.9110e-02, -5.5893e-02,  1.2101e-02, -3.6715e-02, -7.7716e-03,\n",
       "                         2.2244e-03,  7.4673e-02,  1.1302e-01, -6.9717e-02, -5.3680e-02,\n",
       "                        -5.1127e-02, -2.5671e-02, -1.5274e-02,  1.4853e-01, -3.5938e-02,\n",
       "                         1.0221e-01, -8.5980e-03,  1.7404e-02, -1.1086e-02,  8.1833e-03,\n",
       "                         1.4120e-03,  3.9010e-01, -2.9239e-03,  1.9179e-01, -1.8591e-02,\n",
       "                         8.3201e-02, -2.3015e-02,  8.4877e-02, -1.3703e-03, -1.2013e-02,\n",
       "                         2.5559e-03,  1.7272e-03,  3.3393e-02,  2.2096e-03, -6.6838e-03,\n",
       "                        -2.5039e-03,  6.5199e-02, -4.7223e-03,  2.7598e-01,  1.9845e-01,\n",
       "                        -1.6966e-02, -1.6776e-02,  2.9886e-03,  1.1443e-01,  3.2803e-04,\n",
       "                         5.0554e-02, -1.3018e-02, -1.7403e-02,  8.2950e-02,  8.3474e-02,\n",
       "                        -2.0090e-02,  3.3254e-02, -4.2565e-02,  1.0900e-01,  7.0458e-02,\n",
       "                        -3.0497e-02,  9.8335e-02, -8.8841e-03, -6.2446e-02,  1.2595e-01,\n",
       "                         2.7113e-02,  1.2875e-02,  3.3670e-02,  8.8542e-03,  8.5120e-02,\n",
       "                         1.0386e-02, -1.0540e-02,  4.4998e-02,  2.2766e-02,  4.6330e-03,\n",
       "                         4.9211e-03,  2.1697e-03, -3.3382e-02,  4.5957e-02,  4.4243e-03,\n",
       "                         1.0107e-01,  1.7691e-03, -2.6785e-03, -3.2964e-02,  1.9344e-01,\n",
       "                         2.0453e-01,  5.0757e-02,  5.0478e-03,  8.4264e-02, -1.8565e-02,\n",
       "                        -1.2398e-02,  2.3759e-01,  2.1460e-03,  1.5603e-02,  6.5288e-02,\n",
       "                         8.4806e-02, -6.5714e-02,  9.0234e-02,  3.5125e-02,  2.5434e-02,\n",
       "                        -3.6029e-03,  1.4294e-01,  1.8765e-01,  2.0532e-01,  4.6038e-03,\n",
       "                        -4.7747e-04,  2.4076e-01,  1.2592e-01, -5.8910e-02, -2.2147e-02,\n",
       "                        -2.5903e-02,  1.8595e-02,  9.4967e-03,  5.4806e-03,  3.2671e-01,\n",
       "                         1.4033e-01,  9.4308e-02,  9.8202e-02],\n",
       "                       [ 6.0479e-02, -1.0162e-01,  3.5799e-01, -9.9088e-02, -1.1739e-01,\n",
       "                        -2.4835e-01, -8.1181e-02, -2.4208e-02,  8.9509e-02,  6.6143e-02,\n",
       "                        -1.0258e-01,  1.4640e-01,  4.9897e-02,  1.0988e-01, -9.1624e-02,\n",
       "                         6.8900e-02, -1.4008e-02,  1.2583e-01, -3.6688e-02, -1.2709e-01,\n",
       "                        -5.0145e-01,  3.1180e-02,  1.0799e-01, -1.1120e-01, -6.2790e-02,\n",
       "                         1.4102e-01, -1.5235e-01, -1.3006e-01,  1.5143e-01,  3.9789e-02,\n",
       "                         5.1313e-02, -1.1232e-01, -4.6013e-01, -3.3713e-02,  8.6400e-02,\n",
       "                        -7.2232e-02,  3.3566e-01, -9.9984e-02,  1.9213e-01, -1.6845e-02,\n",
       "                         1.0043e-01, -4.1119e-02,  1.4875e-01, -9.7582e-02, -2.8234e-02,\n",
       "                        -1.2203e-01, -1.0012e-01,  7.5767e-02, -2.2430e-01, -2.8564e-01,\n",
       "                        -5.8132e-02,  8.4491e-02, -1.3717e-01,  2.5490e-01,  2.0245e-01,\n",
       "                        -1.9719e-01, -1.4542e-01, -7.0987e-02,  9.0730e-02, -1.0822e-01,\n",
       "                         6.0054e-02, -1.1589e-01, -1.0595e-01,  6.8800e-02,  5.2818e-02,\n",
       "                        -8.2180e-03,  1.2674e-01, -2.5625e-01,  1.1074e-01, -2.8910e-02,\n",
       "                         2.1876e-02,  1.0904e-01, -1.2388e-01, -3.5754e-02, -1.2620e-01,\n",
       "                         7.6250e-02,  1.0202e-01,  4.1924e-02, -1.7600e-01,  6.0868e-02,\n",
       "                        -3.5195e-01, -9.0025e-02,  6.8550e-02, -5.8419e-03, -1.5194e-01,\n",
       "                         8.6764e-02, -3.0279e-01, -2.0771e-01,  7.1331e-02, -9.2967e-02,\n",
       "                         2.7239e-02, -1.5401e-01, -7.9982e-02, -1.0702e-04,  2.0024e-01,\n",
       "                         2.1555e-01,  1.0914e-01, -7.5496e-02,  1.1326e-01, -1.0360e-01,\n",
       "                         1.6173e-01,  2.6241e-01, -5.3794e-02,  1.1923e-01,  6.9135e-02,\n",
       "                         7.8138e-02, -7.7191e-02,  8.6012e-02,  1.2728e-01,  8.4817e-02,\n",
       "                        -3.2339e-02,  1.4232e-01,  1.8143e-01,  2.1540e-01,  4.0939e-02,\n",
       "                        -1.5262e-01,  2.4028e-01,  1.1452e-01,  1.9355e-03, -1.6433e-02,\n",
       "                         1.2483e-01,  6.2317e-02,  3.4045e-02, -1.0764e-01,  3.9021e-01,\n",
       "                         1.2529e-01,  1.4585e-02,  1.1984e-01]])),\n",
       "              ('net.4.bias', tensor([0.0229, 0.0234]))]),\n",
       " 'eps': 0.050000000000000044,\n",
       " 'steps': 0,\n",
       " 'learn_steps': 53944}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Helper: infer expected input dim from a checkpoint/model ---\n",
    "def infer_expected_in_features(model: nn.Module) -> int:\n",
    "    # if model has .net = nn.Sequential(...)\n",
    "    if hasattr(model, \"net\") and isinstance(model.net, nn.Sequential):\n",
    "        for m in model.net:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                return int(m.in_features)\n",
    "    # else, find first Linear anywhere\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Linear):\n",
    "            return int(m.in_features)\n",
    "    raise RuntimeError(\"Could not infer input features (no nn.Linear found).\")\n",
    "\n",
    "def load_checkpoint(path: str):\n",
    "    ckpt = torch.load(path, map_location=\"cpu\")\n",
    "    return ckpt\n",
    "\n",
    "def describe_checkpoint(path: str):\n",
    "    ckpt = load_checkpoint(path)\n",
    "    # Some projects save raw state_dict, others save dict with keys.\n",
    "    if isinstance(ckpt, dict) and \"model_state_dict\" in ckpt:\n",
    "        keys = list(ckpt.keys())\n",
    "        print(f\"Checkpoint {os.path.basename(path)} is a dict with keys:\", keys)\n",
    "        input_dim = ckpt.get(\"input_dim\")\n",
    "        feat_names = ckpt.get(\"feature_names\")\n",
    "        if input_dim is not None:\n",
    "            print(\"  input_dim (stored):\", input_dim)\n",
    "        if feat_names is not None:\n",
    "            print(\"  feature_names (stored) len:\", len(feat_names))\n",
    "            print(\"  first 10:\", feat_names[:10])\n",
    "        return ckpt\n",
    "    else:\n",
    "        print(f\"Checkpoint {os.path.basename(path)} appears to be a raw object/state_dict.\")\n",
    "        return ckpt\n",
    "\n",
    "describe_checkpoint(BUY_CKPT)\n",
    "describe_checkpoint(SELL_CKPT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "059754f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Load your model class to infer expected dim from the actual network ---\n",
    "# # Adjust imports if your classes live elsewhere.\n",
    "# # from agents.ddqn_agent import MLPQNetwork  # change if your class name differs\n",
    "\n",
    "# def load_dqn_from_state_dict(ckpt_path: str, hidden=128):\n",
    "#     ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "\n",
    "#     # If you stored metadata, you can read input_dim from it.\n",
    "#     input_dim = None\n",
    "#     state_dict = None\n",
    "\n",
    "#     if isinstance(ckpt, dict) and \"model_state_dict\" in ckpt:\n",
    "#         state_dict = ckpt[\"model_state_dict\"]\n",
    "#         input_dim = ckpt.get(\"input_dim\")\n",
    "#     elif isinstance(ckpt, dict) and any(k.startswith(\"net.\") for k in ckpt.keys()):\n",
    "#         state_dict = ckpt\n",
    "#     else:\n",
    "#         # Try common key\n",
    "#         if isinstance(ckpt, dict) and \"state_dict\" in ckpt:\n",
    "#             state_dict = ckpt[\"state_dict\"]\n",
    "#         else:\n",
    "#             raise RuntimeError(\"Unknown checkpoint format. Inspect the ckpt in previous cell.\")\n",
    "\n",
    "#     # Infer input dim from first layer weight if not provided\n",
    "#     if input_dim is None:\n",
    "#         # find first linear weight\n",
    "#         for k, v in state_dict.items():\n",
    "#             if k.endswith(\"weight\") and v.ndim == 2:\n",
    "#                 input_dim = int(v.shape[1])\n",
    "#                 break\n",
    "\n",
    "#     if input_dim is None:\n",
    "#         raise RuntimeError(\"Could not infer input_dim from state_dict.\")\n",
    "\n",
    "#     # Your DQN ctor signature may differ. Update as needed.\n",
    "#     model = MLPQNetwork(input_dim=input_dim, hidden_dim=hidden, output_dim=3)  # output_dim placeholder\n",
    "#     model.load_state_dict(state_dict, strict=True)\n",
    "#     model.eval()\n",
    "#     return model, input_dim\n",
    "\n",
    "# buy_model, buy_dim = load_dqn_from_state_dict(BUY_CKPT)\n",
    "# sell_model, sell_dim = load_dqn_from_state_dict(SELL_CKPT)\n",
    "\n",
    "# print(\"BUY expected input dim:\", buy_dim)\n",
    "# print(\"SELL expected input dim:\", sell_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ea886c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: <class 'dict'>\n",
      "top-level keys: ['cfg', 'state_dict', 'target_state_dict', 'eps', 'steps', 'learn_steps']\n",
      "\n",
      "First nested dict key: cfg nested keys sample: ['gamma', 'lr', 'batch_size', 'buffer_size', 'target_update_freq', 'epsilon_start', 'epsilon_end', 'epsilon_decay_steps', 'state_dim', 'n_actions']\n"
     ]
    }
   ],
   "source": [
    "import torch, os\n",
    "ckpt = torch.load(BUY_CKPT, map_location=\"cpu\")\n",
    "print(\"type:\", type(ckpt))\n",
    "if isinstance(ckpt, dict):\n",
    "    print(\"top-level keys:\", list(ckpt.keys())[:50])\n",
    "    # print sample from the first dict-like value\n",
    "    for k,v in ckpt.items():\n",
    "        if isinstance(v, dict):\n",
    "            print(\"\\nFirst nested dict key:\", k, \"nested keys sample:\", list(v.keys())[:20])\n",
    "            break\n",
    "else:\n",
    "    print(\"repr:\", repr(ckpt)[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "673622c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def is_tensor_state_dict(d: dict) -> bool:\n",
    "    if not isinstance(d, dict) or not d:\n",
    "        return False\n",
    "    # state_dict values are usually tensors or tensor-like\n",
    "    return any(torch.is_tensor(v) for v in d.values())\n",
    "\n",
    "def extract_state_dict(ckpt):\n",
    "    # If it's already a tensor state_dict\n",
    "    if isinstance(ckpt, dict) and is_tensor_state_dict(ckpt):\n",
    "        return ckpt\n",
    "\n",
    "    # Common wrappers\n",
    "    if isinstance(ckpt, dict):\n",
    "        for key in [\"model_state_dict\", \"state_dict\", \"q_net_state_dict\", \"policy_state_dict\"]:\n",
    "            if key in ckpt and isinstance(ckpt[key], dict) and is_tensor_state_dict(ckpt[key]):\n",
    "                return ckpt[key]\n",
    "\n",
    "        # Search nested dicts one level deep\n",
    "        for k, v in ckpt.items():\n",
    "            if isinstance(v, dict) and is_tensor_state_dict(v):\n",
    "                return v\n",
    "\n",
    "        # Search deeper (recursive)\n",
    "        stack = [ckpt]\n",
    "        while stack:\n",
    "            cur = stack.pop()\n",
    "            if isinstance(cur, dict):\n",
    "                if is_tensor_state_dict(cur):\n",
    "                    return cur\n",
    "                for v in cur.values():\n",
    "                    if isinstance(v, dict):\n",
    "                        stack.append(v)\n",
    "\n",
    "    # If checkpoint is a Module saved directly\n",
    "    if isinstance(ckpt, nn.Module):\n",
    "        return ckpt.state_dict()\n",
    "\n",
    "    raise RuntimeError(\"Could not find a tensor state_dict inside the checkpoint.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c06e6e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUY cfg: {'gamma': 0.99, 'lr': 0.001, 'batch_size': 64, 'buffer_size': 200000, 'target_update_freq': 500, 'epsilon_start': 1.0, 'epsilon_end': 0.05, 'epsilon_decay_steps': 40000, 'state_dim': 15, 'n_actions': 2}\n",
      "SELL cfg: {'gamma': 0.99, 'lr': 0.001, 'batch_size': 64, 'buffer_size': 200000, 'target_update_freq': 500, 'epsilon_start': 1.0, 'epsilon_end': 0.05, 'epsilon_decay_steps': 48000, 'state_dim': 18, 'n_actions': 2}\n",
      "BUY in_features: 15\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MLPQNetwork(nn.Module):\n",
    "    def __init__(self, state_dim: int, n_actions: int, hidden_sizes=(128, 128)):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        last = state_dim\n",
    "        for h in hidden_sizes:\n",
    "            layers.append(nn.Linear(last, h))\n",
    "            layers.append(nn.ReLU())\n",
    "            last = h\n",
    "        layers.append(nn.Linear(last, n_actions))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "def load_mlp_from_ckpt(path: str):\n",
    "    ckpt = torch.load(path, map_location=\"cpu\")\n",
    "    cfg = ckpt[\"cfg\"]\n",
    "    sd  = ckpt[\"state_dict\"]\n",
    "\n",
    "    model = MLPQNetwork(state_dim=cfg[\"state_dim\"], n_actions=cfg[\"n_actions\"])\n",
    "    model.load_state_dict(sd, strict=True)\n",
    "    model.eval()\n",
    "    return model, cfg\n",
    "\n",
    "buy_model, buy_cfg = load_mlp_from_ckpt(BUY_CKPT)\n",
    "sell_model, sell_cfg = load_mlp_from_ckpt(SELL_CKPT)\n",
    "\n",
    "print(\"BUY cfg:\", buy_cfg)\n",
    "print(\"SELL cfg:\", sell_cfg)\n",
    "print(\"BUY in_features:\", buy_model.net[0].in_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a4abb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Inspect your built dataset dimensions ---\n",
    "features_npy = os.path.join(DATA_DIR, \"features.npy\")\n",
    "prices_npy   = os.path.join(DATA_DIR, \"prices.npy\")\n",
    "\n",
    "X = np.load(features_npy)\n",
    "y = np.load(prices_npy)\n",
    "\n",
    "print(\"features.npy shape:\", X.shape)  # (N, D)\n",
    "print(\"prices.npy shape:\", y.shape)\n",
    "\n",
    "D = X.shape[1]\n",
    "print(\"Built feature dim D =\", D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7da8c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- If you saved row_meta.csv / features.csv, check per-ticker consistency ---\n",
    "if META_CSV and FEATURES_CSV and os.path.exists(META_CSV) and os.path.exists(FEATURES_CSV):\n",
    "    meta = pd.read_csv(META_CSV)\n",
    "    feats = pd.read_csv(FEATURES_CSV)\n",
    "    print(\"meta:\", meta.shape, \"feats:\", feats.shape)\n",
    "\n",
    "    # join row index alignment\n",
    "    assert len(meta) == len(feats)\n",
    "\n",
    "    # check tickers present\n",
    "    print(\"tickers:\", meta['ticker'].unique())\n",
    "\n",
    "    # feature column count\n",
    "    print(\"feature cols:\", feats.shape[1])\n",
    "\n",
    "    # sanity: any NaNs?\n",
    "    nan_rate = feats.isna().mean().sort_values(ascending=False).head(10)\n",
    "    print(\"Top NaN rates:\", nan_rate)\n",
    "else:\n",
    "    print(\"Skipping per-ticker checks. Set META_CSV and FEATURES_CSV paths if you have them.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fed9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Key hypothesis: API-time state builder differs from training-time builder ---\n",
    "# If you can import the function that builds a single 'state' for inference, call it here\n",
    "# and print its length for a few tickers.\n",
    "#\n",
    "# Example (you must adapt to your project):\n",
    "#\n",
    "# from decision.state_builder import build_state_for_ticker\n",
    "# for t in [\"NVDA\",\"AAPL\",\"MSFT\"]:\n",
    "#     s = build_state_for_ticker(t, as_of=None)\n",
    "#     print(t, len(s), s[:5])\n",
    "#\n",
    "# The goal is to find why build_state_for_ticker returns 15 values.\n",
    "#\n",
    "print(\"Next step: point this cell to the exact function used by DecisionEngine to build `state` at inference time.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456c7c82",
   "metadata": {},
   "source": [
    "## What to look for\n",
    "If `features.npy` has D=18 but API-time state has len=15, then your **inference feature builder** is not using the same schema.\n",
    "\n",
    "Common causes:\n",
    "- different config loaded by API (different `technical_indicators` list)\n",
    "- sentiment disabled/enabled inconsistently\n",
    "- state builder dropping missing cols/NaNs\n",
    "\n",
    "If `features.npy` has D=15, but your checkpoint expects 18, you need to **retrain** or **load a checkpoint trained with the new schema**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.14",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
